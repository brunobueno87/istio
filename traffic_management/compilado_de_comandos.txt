Vamos começar ententendo o trafico no cluster com o mesh habilitado.
Então nosso objetivo aqui será, primeiro subir uma aplicação demo no
name space default com o istio injetado nesse namaspace.
Depois iremos criar um novo name space com o nome de test e nesse namespace
iremos criar um pod de test do nginx. Lembrando que esse segundo namespace
não injetaremos o istio.

Sendo assim, vamos em frente...

Verifique o namespace default, possui o istio injetado;
\_#kubectl get ns --show-labels
\_A saída deve ser algo parecido com isso;
NAME              STATUS   AGE     LABELS
default           Active   18d     istio-injection=enabled,kubernetes.io/metadata.name=default
istio-system      Active   16d     kubernetes.io/metadata.name=istio-system
kube-node-lease   Active   18d     kubernetes.io/metadata.name=kube-node-lease
kube-public       Active   18d     kubernetes.io/metadata.name=kube-public
kube-system       Active   18d     kubernetes.io/metadata.name=kube-system

Como eu creio que você já passou pelo passo a passo de instalar e configurar o istio creio que sua saida esta parecida com a minha.

Agora vamos entregar a aplicação demo no namespace default;
\_kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.11/samples/bookinfo/platform/kube/bookinfo.yaml

Verifique se os pods agora estão 2/2 no name spacedefault;
\_ kubectl -n default get pods
NAME                              READY   STATUS    RESTARTS   AGE
details-v1-845dbb5df6-bnwnt       2/2     Running   0          26m
productpage-v1-6997d9c98b-qlnj2   2/2     Running   0          26m
ratings-v1-776d9dddb4-gf7jr       2/2     Running   0          9m37s
reviews-v1-7f594844b-ssgc6        2/2     Running   0          26m
reviews-v2-ff5bdfd46-p2bkc        2/2     Running   0          11m
reviews-v3-5fc846cc6b-jwv69       2/2     Running   0          11m


Show, isso valida que os pods estão ok, e rodando com  o sidecar junto.
Vamos em frente e vamos criar o namespace test;
\_#kubectl create ns test

Agora verifique que esse novo namespace não possui o istio injetado;
\_kubectl get ns --show-labels
NAME              STATUS   AGE   LABELS
default           Active   18d   istio-injection=enabled,kubernetes.io/metadata.name=default
istio-system      Active   16d   kubernetes.io/metadata.name=istio-system
kube-node-lease   Active   18d   kubernetes.io/metadata.name=kube-node-lease
kube-public       Active   18d   kubernetes.io/metadata.name=kube-public
kube-system       Active   18d   kubernetes.io/metadata.name=kube-system
test              Active   10m   kubernetes.io/metadata.name=test

Show, estando tudo certo agora vamos em frente e vamos criar um pod dentro do namespace test;
\_kubectl run test --image=nginx -n test

Verifique que esse novo pod por estar em um namespace sem o istio deve constar como 1/1
Rode o comando;
\_kubectl -n test get pod
NAME   READY   STATUS             RESTARTS   AGE
test   1/1     Running   0          15m

Show, agora vamos ver se existe services no namespace default;
\_ kubectl get svc -n default 
NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
details       ClusterIP   10.97.186.111    <none>        9080/TCP   42m
kubernetes    ClusterIP   10.96.0.1        <none>        443/TCP    18d
productpage   ClusterIP   10.111.74.88     <none>        9080/TCP   42m
ratings       ClusterIP   10.106.222.133   <none>        9080/TCP   42m
reviews       ClusterIP   10.97.129.218    <none>        9080/TCP   42m

Agora entre no pod de test;
\_kubectl exec -ti -n test test -- /bin/bash
root@test:/# curl --head productpage.default.svc.cluster.local:9080
HTTP/1.1 200 OK
content-type: text/html; charset=utf-8
content-length: 1683
server: istio-envoy
date: Thu, 31 Jul 2025 01:03:24 GMT
x-envoy-upstream-service-time: 16
x-envoy-decorator-operation: productpage.default.svc.cluster.local:9080/*

Você recebe um 200, pq por padrão todo o trafego é liberado mesmo com o mesh habilitado.
Agora vamos ativar uma coisa chamada authentication peer. (Nó iremos falar sobre isso de forma
mais aprofundada no modulo de segurança)

Rode o comando;
\_vim peer-auth.yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: dafault
  namespace: default
spec:
  mtls:
    mode: STRICT

Aplique o peer-auth;
\_kubectl apply -f peer-auth.yaml

Agora vamos voltar ao pod de test e rodar o comando mais uma vez;
\_kubectl exec -ti -n test test -- /bin/bash
  \_root@test:/# curl --head productpage.default.svc.cluster.local:9080
    curl: (56) Recv failure: Connection reset by peer
    \_Veja que a saida agora é uma conection reset by peer

Show, isso é pq agora o trafego tem que ser mtls conforme descreve o arquivo peer....yaml que aplicamos.
Para que as coisas voltem ao normal e as duas apps possam se comunicar, vamos injetar o istio no name space de test.
Rode o comando;
\_kubectl label namespace test istio-injection=enabled
  \_Verifique as labels;
     \_kubectl get ns --show-labels
       \_A saida deve ser algo parecido com;
NAME              STATUS   AGE   LABELS
default           Active   19d   istio-injection=enabled,kubernetes.io/metadata.name=default
istio-system      Active   16d   kubernetes.io/metadata.name=istio-system
kube-node-lease   Active   19d   kubernetes.io/metadata.name=kube-node-lease
kube-public       Active   19d   kubernetes.io/metadata.name=kube-public
kube-system       Active   19d   kubernetes.io/metadata.name=kube-system
test              Active   19h   istio-injection=enabled,kubernetes.io/metadata.name=test

Agora delete o pod test;
\_kubectl -n test delete pod test
  \_Crie novamente;
    \_kubectl run test --image=nginx -n test

Agora com pod 2/2 devido o istio estar injetado.
Entre novamente no pod;
\_kubectl exec -ti -n test test -- /bin/bash
  \_Rode o curl novamente;
    \_curl --head productpage.default.svc.cluster.local:9080
      \_A saida deve ser um 200, algo parecido com o exemplo abaixo;
HTTP/1.1 200 OK
content-type: text/html; charset=utf-8
content-length: 1683
server: envoy
date: Thu, 31 Jul 2025 20:20:49 GMT
x-envoy-upstream-service-time: 54

Show, vamos em frente e agora vamos criar um sidecar.
Crie o yaml sidecar_default_namespace.yaml com o seguinte conteudo;
apiVersion: networking.istio.io/v1beta1
kind: Sidecar
metadata:
  name: default
  namespace: test
spec:
  egress:
  - hosts:
    - "./*"
    - "istio-system/*"

Agora aplique;
\_kubectl apply -f sidecar_default_namespace.yaml

Entre novamente no pod de test;
\_kubectl exec -ti -n test test -- /bin/bash
  \_Roda novamente o curl;
    \_root@test:/# curl --head productpage.default.svc.cluster.local:9080
      \_A resposta esperada é algo parecido com o exemplo abaixo;
        curl: (52) Empty reply from server

Isso por que o sidecar desse namespace não permite trafego de saida para o namespace default, altere o
sidecar_default_namespace.yaml e adicione o namespace default;
\_vim sidecar_default_namespace.yaml
apiVersion: networking.istio.io/v1beta1
kind: Sidecar
metadata:
  name: default
  namespace: test
spec:
  egress:
  - hosts:
    - "./*"
    - "default/*"
    - "istio-system/*"

Aplique;
\_kubectl apply -f sidecar_default_namespace.yaml
  Entre novamente no pod de test;
  \_kubectl exec -ti -n test test -- /bin/bash
    E roda novamente o curl de test;
    \_curl --head productpage.default.svc.cluster.local:9080
      \_A saida é algo parecido com o exemplo abaixo;
HTTP/1.1 200 OK
content-type: text/html; charset=utf-8
content-length: 1683
server: envoy
date: Thu, 31 Jul 2025 20:50:39 GMT
x-envoy-upstream-service-time: 21

É isso por enquanto é só, isso foi para termos nosso primeiro contato com o gerenciamento de trafego começar a entender a comunicação no cluster quando utilizamos o istio.

Vamos em frente e agora, vamos começar a entender  Virtual Services, vá para o diretório do Virtual Service e continue aprendendo. 

Forte abraço, tudo de bom. =)
